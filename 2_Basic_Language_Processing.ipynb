{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Basic_Language_Processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lbiester/AI4All-UM-NLP/blob/master/2_Basic_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zpma3K1a8VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    %cd '/content/drive/My Drive/AI4All-UM-NLP'\n",
        "\n",
        "    import nltk\n",
        "    nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T3qjGEya3VH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import lib\n",
        "import spacy\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import statistics\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvlBvxpxa3VK",
        "colab_type": "text"
      },
      "source": [
        "# Basic Language Processing\n",
        "Now that we know a little bit about the demographics of the workers who helped to produce the dataset, let's start looking at the language! There are a few questions that we want to answer:\n",
        "* What makes people happy?\n",
        "* Do the things that cause happiness differ between groups?\n",
        "\n",
        "We'll start by using some simple techniques to answer the first question!\n",
        "\n",
        "First, though, we need to pre-process the data. We will create a new map that maps hmid to a list of \"tokens\" in the cleaned happy moment text. You can think of a token as an individual word. To tokenize text, use the function `nltk.word_tokenize` from the nltk library. Make each token lowercase.\n",
        "\n",
        "You should also create a list of all tokens in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy5w2f-Ma3VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joined_data = lib.load_joined_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX33znxYa3VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_hm_tokens(joined_data):\n",
        "    hm_tokens = {}\n",
        "    for hm in joined_data:\n",
        "        hm_tokens[hm['hmid']] = []\n",
        "        for token in nltk.word_tokenize(hm['hm_text']):\n",
        "            hm_tokens[hm['hmid']].append(token.lower())\n",
        "    return hm_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0eaTigfa3VP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hm_tokens = get_hm_tokens(joined_data)\n",
        "all_tokens = list(itertools.chain.from_iterable(hm_tokens.values()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMdkiwQa3VQ",
        "colab_type": "text"
      },
      "source": [
        "## Wordclouds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM8LSExOa3VR",
        "colab_type": "text"
      },
      "source": [
        "One way in which we can visualize text data is by using a word cloud. This will show us which words appear frequently in the text. Luckily, we don't need to write a bunch of code to display a word cloud - libraries exist to do it already! We have a function that can be used to create word clouds in the library, `lib.create_word_cloud`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0C8nkPza3VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib.create_word_cloud(all_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbZh-PKaa3VU",
        "colab_type": "text"
      },
      "source": [
        "Now let's do something a bit more interesting: later on, we will classify happiness posts by if they are made by a man or a woman. Let's create two word clouds: one of posts made by men, and one of posts made by women, and see how they differ. This will require two steps\n",
        "\n",
        "1. Separate out tokens in entries written by women and entries written by men\n",
        "1. Create word clouds of each"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFqNi3ma3VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "man_tokens = []\n",
        "woman_tokens = []\n",
        "for hm in joined_data:\n",
        "    if hm['gender'] == 'm':\n",
        "        man_tokens.extend(hm_tokens[hm['hmid']])\n",
        "    elif hm['gender'] == 'f':\n",
        "        woman_tokens.extend(hm_tokens[hm['hmid']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5EHBLy5a3VX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib.create_word_cloud(man_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AdyJ72ja3VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib.create_word_cloud(woman_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdIQhrUEa3Va",
        "colab_type": "text"
      },
      "source": [
        "You probably notice a few differences between the word clouds - take a minute to jot some of them down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL3tzC2ta3Vb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3O2Uaqea3Vc",
        "colab_type": "text"
      },
      "source": [
        "Even though there are some differences, you'll probably notice that the word clouds look quite similar overall. Words that don't seem to meaningful like \"made happy\" and \"got\" are large in both word clouds.\n",
        "\n",
        "There are many ways that we can remove words that aren't meaningful. One typical approach is to use a \"stopwords\" list, which will include function words like \"the\", \"a\", \"an\", etc.\n",
        "\n",
        "The wordcloud library actually has a built-in list of stopwords, but we also should filter out some words that are common in happy moments even if they aren't common in written text overall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p7PcKuca3Vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: I'm currently doing this programmatically. I could ask the students to do it this way, or ask them to come up \n",
        "# with their own list. There are probably also smarter ways to do this, this is just a starting point\n",
        "\n",
        "common_female_words = set(k for k, v in Counter(woman_tokens).most_common(100))\n",
        "common_male_words = set(k for k, v in Counter(man_tokens).most_common(100))\n",
        "stop = common_female_words.intersection(common_male_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DxNI9hna3Ve",
        "colab_type": "text"
      },
      "source": [
        "After you have your personal stopwords list, pass it in to the word cloud function like this: `lib.create_word_cloud(tokens, stop=stop)` (it is an optional parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu06kb8ia3Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib.create_word_cloud(man_tokens, stop=stop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzPXlcn3a3Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lib.create_word_cloud(woman_tokens, stop=stop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQKX07Y2a3Vi",
        "colab_type": "text"
      },
      "source": [
        "Hopefully, you now see more noticeable differences between the word clouds.\n",
        "\n",
        "Feel free to play around with the word clouds with different attributes, like age and country!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkUqg46ta3Vj",
        "colab_type": "text"
      },
      "source": [
        "## Word Count\n",
        "Something else that might differ between men and women is the number of words included in what they write. Collect the overall average word count, in addition to average for men and average for women. What do you find?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvBq09L5a3Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Overall average:', statistics.mean(len(tokens) for hmid, tokens in hm_tokens.items()))\n",
        "print('Male average:', statistics.mean(len(hm_tokens[hm['hmid']]) for hm in joined_data if hm['gender'] == 'm'))\n",
        "print('Female average:', statistics.mean(len(hm_tokens[hm['hmid']]) for hm in joined_data if hm['gender'] == 'f'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jx1ceWJa3Vm",
        "colab_type": "text"
      },
      "source": [
        "Who tends to write more? What about parental status? Do parents write more or less than non-parents?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWWxocrMa3Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Parent average:', statistics.mean(len(hm_tokens[hm['hmid']]) for hm in joined_data if hm['parenthood'] == 'y'))\n",
        "print('Non-parent average:', statistics.mean(len(hm_tokens[hm['hmid']]) for hm in joined_data if hm['parenthood'] == 'n'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcUbGJWRa3Vo",
        "colab_type": "text"
      },
      "source": [
        "It seems as though parents write a bit more than non-parents! Why do you think that could be?\n",
        "\n",
        "Ultimately, word count does not tell us much about what makes different groups happy. However, it could be a useful tool when predicting who a happy moment description comes from. We will explore this more later. It does seem as though the word clouds, which represent which words are most frequently used when people talk about what makes them happy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL7Rvbuza3Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOlI3F8Ua3Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}